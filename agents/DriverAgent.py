import sys
from pathlib import Path
import json

# Add root project directory to sys.path
sys.path.append(str(Path(__file__).resolve().parent.parent))



from typing import Dict, List, Optional, Any, TypedDict, Annotated, Union

from utils.modelRelated import invoke_model, invoke_model_with_tools

from pathlib import Path
# Create an interactive chatbox using gradio
from dotenv import load_dotenv


from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
# from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool

# import other agents
from agents.processUserInput import ProcessUserInputAgent

load_dotenv()

def append_strings(left: list[str], right: Union[list[str], str]) -> list[str]:
    """Custom reducer to append strings to a list"""
    if isinstance(right, list):
        return left + right
    else:
        return left + [right]
    

@tool
def _collect_user_input(session_id: str, AI_question: str, village_name: str) -> str:
    """è¿™æ˜¯ä¸€ä¸ªç”¨æ¥æ”¶é›†ç”¨æˆ·è¾“å…¥çš„å·¥å…·ï¼Œä½ éœ€è¦è°ƒç”¨è¿™ä¸ªå·¥å…·æ¥æ”¶é›†ç”¨æˆ·è¾“å…¥
    å‚æ•°ï¼š
        session_id: å½“å‰ä¼šè¯ID
        AI_question: å¤§æ¨¡å‹çš„é—®é¢˜
        village_name: å½“å‰æ‘å
    è¿”å›ï¼š
        str: æ€»ç»“åçš„ç”¨æˆ·è¾“å…¥ä¿¡æ¯
    """

    print(f"ğŸ”„ å¼€å§‹æ”¶é›†ç”¨æˆ·è¾“å…¥ï¼Œå½“å‰ä¼šè¯ID: {session_id}")
    print(f"ğŸ’¬ AIé—®é¢˜: {AI_question}")
    
    processUserInputAgent = ProcessUserInputAgent()
    ai_message = AIMessage(content=AI_question)
    response = processUserInputAgent.run_process_user_input_agent(session_id = session_id, 
                                                                  previous_AI_messages = ai_message,
                                                                  village_name = village_name)
    print(f"ğŸ”„ è¿”å›å“åº”: {response[:100]}...")
    return response
    

class FrontdeskState(TypedDict):
    chat_history: Annotated[list[str], append_strings]
    messages: Annotated[list[BaseMessage], add_messages]
    previous_node: str # Track the previous node
    session_id: str
    village_name: str


class FrontdeskAgent:
    """
    ç”¨äºå¤„ç†ç”¨æˆ·ä¸Šä¼ çš„æ¨¡æ¿ï¼Œè‹¥æœªæä¾›æ¨¡æ¿ï¼Œå’Œç”¨æˆ·æ²Ÿé€šç¡®å®šè¡¨æ ¼ç»“æ„
    """



    def __init__(self, model_name: str = "gpt-4o"):
        self.model_name = model_name
        self.tools = [_collect_user_input]
        self.graph = self._build_graph()




    def _build_graph(self):
        """This function will build the graph of the frontdesk agent"""

        graph = StateGraph(FrontdeskState)

        graph.add_node("entry", self._entry_node)
        graph.add_node("collect_user_input", ToolNode(self.tools))
        graph.add_node("initial_collect_user_input", self._initial_collect_user_input)


        graph.add_edge(START, "entry")
        graph.add_edge("entry", "initial_collect_user_input")
        graph.add_conditional_edges("initial_collect_user_input", self._route_after_initial_collect_user_input,
                                    {
                                        "initial_collect_user_input": "initial_collect_user_input"
                                    })
        graph.add_conditional_edges("collect_user_input", self._route_after_collect_user_input)

        
        # Compile the graph to make it executable with stream() method
        # You can add checkpointer if needed: graph.compile(checkpointer=MemorySaver())
        return graph.compile()



    def _create_initial_state(self, session_id: str = "1", village_name: str = "") -> FrontdeskState:
        """This function will create the initial state of the frontdesk agent"""
        return {
            "chat_history": [],
            "messages": [],
            "session_id": session_id,
            "previous_node": "",
            "village_name": village_name
        }


    def _entry_node(self, state: FrontdeskState) -> FrontdeskState:
        """This is the starting node of our frontdesk agent"""
        print("\nğŸš€ å¼€å§‹æ‰§è¡Œ: _entry_node")
        print("=" * 50)
        
        # Enrich this later, it should include a short description of the agent's ability and how to use it
        welcome_message = "ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€ä¸ªè¡¨æ ¼å¤„ç†åŠ©æ‰‹ï¼"
        print(f"ğŸ’¬ æ¬¢è¿æ¶ˆæ¯: {welcome_message}")
        
        print("âœ… _entry_node æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        
        return {
            "messages": [AIMessage(content=welcome_message)],
        }
    

    def _initial_collect_user_input(self, state: FrontdeskState) -> FrontdeskState:
        """è°ƒç”¨ProcessUserInputAgentæ¥æ”¶é›†ç”¨æˆ·è¾“å…¥"""
        print("\nğŸ” å¼€å§‹æ‰§è¡Œ: _initial_collect_user_input")
        print("=" * 50)
        
        session_id = state["session_id"]
        previous_AI_messages = state["messages"][-1]
        
        print(f"ğŸ“‹ ä¼šè¯ID: {session_id}")
        print("ğŸ”„ æ­£åœ¨è°ƒç”¨ProcessUserInputAgent...")
        
        processUserInputAgent = ProcessUserInputAgent()
        summary_message = processUserInputAgent.run_process_user_input_agent(session_id = session_id, 
                                                                             previous_AI_messages = previous_AI_messages,
                                                                             village_name = state["village_name"],
                                                                             current_node = "initial_collect_user_input")
        print(f"ğŸ“¥ åŸå§‹è¿”å›ä¿¡æ¯ï¼š{summary_message}")
        
        # Handle the case where summary_message might be None
        if summary_message is None or len(summary_message) < 2:
            error_msg = "ç”¨æˆ·è¾“å…¥å¤„ç†å¤±è´¥ï¼Œè¯·é‡æ–°è¾“å…¥"
            print(f"âŒ {error_msg}")
            print("âœ… _initial_collect_user_input æ‰§è¡Œå®Œæˆ(é”™è¯¯)")
            print("=" * 50)
            return {
                "messages": [AIMessage(content=error_msg)],
                "template_file_path": summary_message[1],
                "previous_node": "initial_collect_user_input"
            }
            
        print(f"ğŸ“Š è¿”å›ä¿¡æ¯JSON dumpï¼š{json.dumps(summary_message[0])}")
        
        print("âœ… _initial_collect_user_input æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        print("tempalte_file_paathåˆå§‹åŒ–: ", summary_message[1])
        return {
            "messages": [AIMessage(content=summary_message[0])],
            "template_file_path": summary_message[1],
        }
        
    def _route_after_initial_collect_user_input(self, state: FrontdeskState) -> str:
        """åˆå§‹è°ƒç”¨ProcessUserInputAgentåï¼Œæ ¹æ®è¿”å›ä¿¡æ¯å†³å®šä¸‹ä¸€æ­¥çš„æµç¨‹"""
        print("\nğŸ”€ å¼€å§‹æ‰§è¡Œ: _route_after_initial_collect_user_input")
        print("=" * 50)
        
        content = state['messages'][-1].content
        print(f"ğŸ“‹ stateæµ‹è¯•: {content}")
        
        # Check if content is JSON or plain text error message
        try:
            summary_message = json.loads(content)
            print(f"ğŸ“Š summary_messageæµ‹è¯•: {summary_message}")
            next_node = summary_message.get("next_node", "previous_node")
            print(f"ğŸ”„ è·¯ç”±å†³å®š: {next_node}")
            
            print("âœ… _route_after_initial_collect_user_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
                
            if next_node == "complex_template":
                # Complex template handling not implemented yet, fallback to simple template
                print("âš ï¸ å¤æ‚æ¨¡æ¿å¤„ç†æš‚æœªå®ç°ï¼Œè½¬ä¸ºç®€å•æ¨¡æ¿å¤„ç†")
                return "simple_template_handle"
            elif next_node == "simple_template":
                return "simple_template_handle"
            else:
                return next_node  # Fallback to previous node
                
        except json.JSONDecodeError:
            # Content is plain text error message, not JSON
            print("âŒ å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œå¯èƒ½æ˜¯é”™è¯¯æ¶ˆæ¯")
            print("ğŸ”„ è·¯ç”±åˆ° chat_with_user_to_determine_template é‡æ–°å¼€å§‹")
            print("âœ… _route_after_initial_collect_user_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            return "chat_with_user_to_determine_template"
        

    def _route_after_collect_user_input(self, state: FrontdeskState) -> str:
        """This node will route the agent to the next node based on the summary message from the ProcessUserInputAgent"""
        print("\nğŸ”€ å¼€å§‹æ‰§è¡Œ: _route_after_collect_user_input")
        print("=" * 50)
        
        latest_message = state["messages"][-1]
        
        # This is a regular message, try to parse as JSON for routing
        summary_message_str = latest_message.content
        print(f"ğŸ“‹ åŸå§‹å†…å®¹: {summary_message_str}")
        
        try:
            summary_message_json = json.loads(summary_message_str)
            summary_message = json.loads(summary_message_json[0])
            print(f"ğŸ“Š summary_messageæµ‹è¯•: {summary_message}")
            next_node = summary_message.get("next_node", "previous_node")
            print(f"ğŸ”„ è·¯ç”±å†³å®š: {next_node}")
            
            print("âœ… _route_after_collect_user_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
                
            if next_node == "complex_template":
                # Complex template handling not implemented yet, fallback to simple template
                print("âš ï¸ å¤æ‚æ¨¡æ¿å¤„ç†æš‚æœªå®ç°ï¼Œè½¬ä¸ºç®€å•æ¨¡æ¿å¤„ç†")
                return "simple_template_handle"
            elif next_node == "simple_template":
                return "simple_template_handle"
            else:
                return state.get("previous_node", "entry")  # Fallback to previous node
                
        except json.JSONDecodeError:
            # Content is plain text error message, not JSON
            print("âŒ å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œå¯èƒ½æ˜¯é”™è¯¯æ¶ˆæ¯")
            print("ğŸ”„ è·¯ç”±åˆ° chat_with_user_to_determine_template é‡æ–°å¼€å§‹")
            print("âœ… _route_after_collect_user_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            return "chat_with_user_to_determine_template"
            

    
    def run_frontdesk_agent(self, session_id: str = "1", village_name: str = "") -> None:
        """This function will run the frontdesk agent using stream method with interrupt handling"""
        print("\nğŸš€ å¯åŠ¨ FrontdeskAgent")
        print("=" * 60)
        
        initial_state = self._create_initial_state(session_id, village_name)
        config = {"configurable": {"thread_id": session_id}}
        current_state = initial_state

        while True:
            try:
                print(f"\nğŸ”„ æ‰§è¡ŒçŠ¶æ€å›¾ï¼Œå½“å‰ä¼šè¯ID: {session_id}")
                print("-" * 50)
                
                final_state = self.graph.invoke(current_state, config = config)
                if "__interrupt__" in final_state:
                    interrupt_value = final_state["__interrupt__"][0].value
                    print(f"ğŸ’¬ æ™ºèƒ½ä½“: {interrupt_value}")
                    user_response = input("ğŸ‘¤ è¯·è¾“å…¥æ‚¨çš„å›å¤: ")
                    current_state = Command(resume=user_response)
                    continue
                print("FrontdeskAgentæ‰§è¡Œå®Œæ¯•")
                break
                
            except Exception as e:
                print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                print("-" * 50)
                break

            

frontdesk_agent = FrontdeskAgent()
graph = frontdesk_agent.graph



if __name__ == "__main__":

    frontdesk_agent = FrontdeskAgent()
    frontdesk_agent.run_frontdesk_agent(village_name="ç‡•äº‘æ‘")